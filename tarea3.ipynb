{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6701ac",
   "metadata": {},
   "source": [
    "# Assignment: Convolutional Neural Networks\n",
    "\n",
    "## 1. Dataset Exploration (EDA)\n",
    "We will use the **CIFAR-10** dataset. It consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.\n",
    "\n",
    "### Why CIFAR-10?\n",
    "- **Image-based**: 32x32 RGB images.\n",
    "- **Multi-class**: 10 distinct classes.\n",
    "- **Complexity**: Standard benchmark where CNNs significantly outperform dense networks, making it ideal for this comparison.\n",
    "- **Size**: Fits comfortably in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be3245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaec74f",
   "metadata": {},
   "source": [
    "### Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training images shape: {train_images.shape}\")\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "print(f\"Training labels shape: {train_labels.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(train_labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84283191",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "Let's view 25 random images from the training set to understand the data diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i])\n",
    "    # The CIFAR labels happen to be arrays, \n",
    "    # which is why you need the extra index\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565b5d3a",
   "metadata": {},
   "source": [
    "## 2. Baseline Model (Non-Convolutional)\n",
    "We will implement a simple Multi-Layer Perceptron (MLP) consisting only of Dense (Fully Connected) layers.\n",
    "\n",
    "**Architecture:**\n",
    "- Flatten input (32x32x3 -> 3072)\n",
    "- Dense Layer (512 units, ReLU)\n",
    "- Dense Layer (256 units, ReLU)\n",
    "- Output Layer (10 units, Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8878c2",
   "metadata": {},
   "source": [
    "### Training the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e740b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "baseline_history = baseline_model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d9670",
   "metadata": {},
   "source": [
    "## 3. Convolutional Architecture Design\n",
    "Now we design a CNN from scratch. \n",
    "\n",
    "**Architecture:**\n",
    "- **Conv2D**: 32 filters, 3x3 kernel. Extracts low-level features.\n",
    "- **MaxPooling2D**: 2x2. Reduces spatial dimensions.\n",
    "- **Conv2D**: 64 filters, 3x3 kernel. Extracts higher-level features.\n",
    "- **MaxPooling2D**: 2x2.\n",
    "- **Conv2D**: 64 filters, 3x3 kernel.\n",
    "- **Flatten**: Converts 3D volume to 1D vector.\n",
    "- **Dense**: 64 units, ReLU. Interpretation layer.\n",
    "- **Output**: 10 units. Classification.\n",
    "\n",
    "**Justification:**\n",
    "We use a stack of Conv2D and MaxPooling2D layers to progressively extract features and downsample the image. The number of filters increases (32 -> 64) as we go deeper to capture more complex patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e085c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = models.Sequential()\n",
    "cnn_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Add Dense layers on top\n",
    "cnn_model.add(layers.Flatten())\n",
    "cnn_model.add(layers.Dense(64, activation='relu'))\n",
    "cnn_model.add(layers.Dense(10))\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506119c9",
   "metadata": {},
   "source": [
    "### Training the CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e144195",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "cnn_history = cnn_model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
